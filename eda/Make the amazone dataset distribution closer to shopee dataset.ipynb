{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python3\n",
    "'''\n",
    "Created on July 9 2018\n",
    "\n",
    "@author: Ray\n",
    "\n",
    "Reference: Attribute Extraction from Product Titles in eCommerce.\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "from datetime import datetime # for the newest version control\n",
    "import sys\n",
    "sys.path.append('../brand_detector/preprocessing/')\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "from clean_helpers import clean_name\n",
    "import logging\n",
    "def brand_split_validating_strategy(df, train_val_rate = 0.8, dataset_source = 'Amazon'):\n",
    "    '''\n",
    "    It's helper function for spliting df into training and validating dataset \n",
    "    based on unique brand because we hope our model can detect those unseen brands.\n",
    "    \n",
    "    parameters:\n",
    "    -----------------\n",
    "    df: DataFrame\n",
    "    train_val_rate: float, where range is (0,1]\n",
    "    dataset_source: str, for telling/differentiating different dataset\n",
    "    '''\n",
    "    if dataset_source == 'Amazon':\n",
    "        #--------------\n",
    "        # create a dataframe for splitting\n",
    "        #--------------  \n",
    "        brand_stat = df.what_brand_name.value_counts().to_frame('count') \\\n",
    "        .reset_index().rename(columns = {'index':'what_brand_name'})\n",
    "        brand_stat['percent'] =  brand_stat['count'] / brand_stat['count'].sum()\n",
    "        #--------------\n",
    "        # core\n",
    "        #--------------\n",
    "        training_brand = []\n",
    "        validating_brand = []\n",
    "        cumulative_percent = 0 \n",
    "        for ix, row in brand_stat.sample(frac = 1.0).iterrows():\n",
    "            # shuffle the dataframe, for avoiding our training data all are big brands.\n",
    "            if row['what_brand_name'] != 'Others':\n",
    "                cumulative_percent += row['percent']\n",
    "                if cumulative_percent <= train_val_rate:\n",
    "                    training_brand.append(row['what_brand_name'])\n",
    "                else:\n",
    "                    validating_brand.append(row['what_brand_name']) \n",
    "\n",
    "        #--------------\n",
    "        # unit testing for if there is no same brand name in the train and val set.\n",
    "        #--------------\n",
    "        percent_train = brand_stat[brand_stat.what_brand_name.isin(training_brand)].percent.sum()\n",
    "        unique_brand_train = set(brand_stat[brand_stat.what_brand_name.isin(training_brand)].what_brand_name.tolist())\n",
    "        percent_val = brand_stat[brand_stat.what_brand_name.isin(validating_brand)].percent.sum()\n",
    "        unique_brand_val = set(brand_stat[brand_stat.what_brand_name.isin(validating_brand)].what_brand_name.tolist())\n",
    "        print ('no bugging in unit testing' if unique_brand_val.intersection(unique_brand_train) == set() else 'Opps, there are same brand name in train and val.')\n",
    "        #--------------\n",
    "        # output\n",
    "        #--------------    \n",
    "        df1 = df[df.what_brand_name.isin(training_brand)]\n",
    "        df2 = df[df.what_brand_name.isin(validating_brand)]\n",
    "        df1['is_valid'] = 0\n",
    "        df2['is_valid'] = 1\n",
    "        # combination\n",
    "        df = pd.concat([df1, df2], axis = 0)\n",
    "        del df1, df2, brand_stat, training_brand, validating_brand\n",
    "        gc.collect() \n",
    "    elif dataset_source == 'Shopee':\n",
    "        #--------------\n",
    "        # create a dataframe for splitting\n",
    "        #--------------  \n",
    "        brand_stat = df.what_brand_name.value_counts().to_frame('count') \\\n",
    "        .reset_index().rename(columns = {'index':'what_brand_name'})\n",
    "        brand_stat['percent'] =  brand_stat['count'] / brand_stat['count'].sum()\n",
    "        #--------------\n",
    "        # core\n",
    "        #--------------\n",
    "        # initialize variables\n",
    "        testing_brand = []\n",
    "        training_brand = []\n",
    "        validating_brand = []\n",
    "        cumulative_percent = 0 \n",
    "        # shuffle the dataframe, for avoiding our training data all are big brands.\n",
    "        for ix, row in brand_stat.sample(frac = 1.0).iterrows():\n",
    "            cumulative_percent += row['percent']\n",
    "            if cumulative_percent <= 0.5:\n",
    "                # take 0.5 as testing_brand\n",
    "                testing_brand.append(row['what_brand_name'])\n",
    "            elif 0.5 < cumulative_percent <= 0.85:\n",
    "                # take 0.35 as training_brand\n",
    "                training_brand.append(row['what_brand_name'])\n",
    "            else:\n",
    "                # take the rest 0.15 as validating_brand\n",
    "                validating_brand.append(row['what_brand_name'])\n",
    "        #--------------\n",
    "        # unit testing\n",
    "        #--------------\n",
    "        percent_train = brand_stat[brand_stat.what_brand_name.isin(training_brand)].percent.sum()\n",
    "        unique_brand_train = set(brand_stat[brand_stat.what_brand_name.isin(training_brand)].what_brand_name.tolist())\n",
    "        percent_val = brand_stat[brand_stat.what_brand_name.isin(validating_brand)].percent.sum()\n",
    "        unique_brand_val = set(brand_stat[brand_stat.what_brand_name.isin(validating_brand)].what_brand_name.tolist())\n",
    "        print ('no bugging in unit testing' if unique_brand_val.intersection(unique_brand_train) == set() else 'Opps, there are same brand name in train and val.')\n",
    "        #--------------\n",
    "        # output\n",
    "        #--------------    \n",
    "        df1 = df[df.what_brand_name.isin(testing_brand)]\n",
    "        df2 = df[df.what_brand_name.isin(training_brand)]\n",
    "        df3 = df[df.what_brand_name.isin(validating_brand)]\n",
    "\n",
    "        df1['is_valid'] = 2 # 2:testing\n",
    "        df2['is_valid'] = 0 # 0:training\n",
    "        df3['is_valid'] = 1 # 1:validating\n",
    "\n",
    "        # combination\n",
    "        df = pd.concat([df1, df2, df3], axis = 0)\n",
    "        del df1, df2, df3, brand_stat, training_brand, validating_brand   \n",
    "        gc.collect()\n",
    "    else:\n",
    "        print ('FUCK YOU, the dataset u provided is WRONG, please usee Amazon or Shopee')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def sequence_labeling_w_bio_encoding(row):\n",
    "    '''\n",
    "    BIO encoding is a distant supervision approach to automatically generate training data for training machine- earning based model. \n",
    "    \n",
    "    Reference for distant supervision approach: http://deepdive.stanford.edu/distant_supervision\n",
    "    Reference for BIO : Attribute Extraction from Product Titles in eCommerce.\n",
    "    Assumption:\n",
    "        - We assume that one sku only has one brand name.(kind of non-realistic)\n",
    "    parameters:\n",
    "    --------------\n",
    "    df: DataFrame\n",
    "    if_assumption: str. if True, we assume we only have one-single brand_word in one item_name. \n",
    "    Otherwise, we can have multiple token with positive lable in one item_name.\n",
    "    '''\n",
    "\n",
    "    # initialize variables\n",
    "    word_list = []\n",
    "    tagging = [] # multi-class label, {0:not part of the brand name, 1: intermediate part of the brand name, 2:beginning of the brand name}\n",
    "    item_name = []\n",
    "    val = [] \n",
    "    #---------------\n",
    "    # sequential labeling with BIO encoding\n",
    "    #---------------\n",
    "    brand_started = False\n",
    "    b_ix = 0\n",
    "    brand = row.what_brand_name.iloc[0].split(' ')\n",
    "    title = clean_name(row['item_name'].iloc[0]).split(' ')\n",
    "    # filter\n",
    "    title = [t for t in title if '' != t]\n",
    "    for w_ix, word in enumerate(title):\n",
    "        if word.lower() == brand[0].lower():\n",
    "            tagging.append(2) # B-B: 2\n",
    "            brand_started = True\n",
    "            b_ix += 1\n",
    "        elif (len(brand) > 1) and (brand_started):\n",
    "            if b_ix >= len(brand):\n",
    "                # for avoiding . For example, if 'BUMBLE AND BUMBLE by Bumble and Bumble: QUENCHING CONDITIONER 8.5 OZ'\n",
    "                tagging.append(0) # O: 0\n",
    "                brand_started = False  \n",
    "                b_ix = 0                \n",
    "            else:\n",
    "                if word.lower() == brand[b_ix].lower():\n",
    "                    tagging.append(1) # I-B: 1\n",
    "                    b_ix += 1\n",
    "                    if b_ix == len(brand):\n",
    "                        # go back to orginal state because we already marked what we want\n",
    "                        brand_started = False\n",
    "                        b_ix = 0\n",
    "                else:\n",
    "                    tagging.append(0) # O: 0\n",
    "                    brand_started = False     \n",
    "                    # if we need to modified the labeling we priviously marked.\n",
    "                    if b_ix < len(brand):\n",
    "                        go_back_to_modified = 0\n",
    "                        for i in range(b_ix):\n",
    "                            #print ('w_ix', w_ix) # w_ix 對應的不是整個 tagging的list: 兩個解法, 1.groupby 2.w_ix要一直被加上\n",
    "                            go_back_to_modified += 1\n",
    "                            #print ('go back', w_ix - go_back_to_modified)\n",
    "                            tagging[w_ix - go_back_to_modified] = 0 # O: 0\n",
    "                        # Once removing privous labeling, we update b_ix to zero\n",
    "                        b_ix = 0         \n",
    "        else:\n",
    "            brand_started = False\n",
    "            tagging.append(0) # O: 0\n",
    "        #---------------------------\n",
    "        # for output dataframe\n",
    "        #---------------------------\n",
    "        if NORMALIZED == True:\n",
    "            word_list.append(word.lower())\n",
    "        else:\n",
    "            word_list.append(word)\n",
    "        item_name.append(clean_name(row['item_name'].iloc[0]))\n",
    "        val.append(row['is_valid'].iloc[0])\n",
    "    #---------------------------\n",
    "    # output\n",
    "    #---------------------------\n",
    "    df = pd.DataFrame({'tokens':word_list, \n",
    "                'is_brand': tagging,\n",
    "                'is_valid': val,\n",
    "                'item_name':item_name})[['item_name','tokens','is_brand','is_valid']]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no bugging in unit testing\n",
      "no bugging in unit testing\n",
      "no bugging in unit testing\n",
      "no bugging in unit testing\n"
     ]
    }
   ],
   "source": [
    "#--------------------------\n",
    "# setting\n",
    "#--------------------------\n",
    "seed = 1030\n",
    "NORMALIZED = False\n",
    "np.random.seed(seed)\n",
    "\n",
    "#--------------------------\n",
    "# loading data (TV and Laptop) / shopee\n",
    "#--------------------------\n",
    "# Note the below\n",
    "bath_path_1 = '../../grouping/tv_and_laptop_grouping/output/laptop/2018-08-07/'\n",
    "bath_path_2 = '../../grouping/tv_and_laptop_grouping/output/tv/2018-08-07/'\n",
    "df_laptop = pd.read_csv(os.path.join(bath_path_1,'TH-laptop_for_brand_detector.csv'))\n",
    "df_tv = pd.read_csv(os.path.join(bath_path_2,'TH-TV_for_brand_detector.csv'))\n",
    "# cobine tv and laptop data\n",
    "df_all = pd.concat([df_laptop, df_tv], axis = 0)\n",
    "# take all the sku that we can find brand from catalogue list as train\n",
    "tv_and_laptop = df_all[df_all.if_tokens_of_cleaned_name_is_in_raw_brand == 1]\n",
    "# cleaning duplicated item_name\n",
    "tv_and_laptop = tv_and_laptop.drop_duplicates(subset = ['item_name'])\n",
    "# make the index unique\n",
    "tv_and_laptop.index = np.arange(tv_and_laptop.shape[0]) \n",
    "# convert type into str\n",
    "tv_and_laptop.item_name = tv_and_laptop.item_name.astype(str)\n",
    "tv_and_laptop.what_brand_name = tv_and_laptop.what_brand_name.astype(str)\n",
    "# clean memory\n",
    "del df_laptop, df_tv, df_all\n",
    "gc.collect()\n",
    "\n",
    "#--------------------------\n",
    "# loading data (personal care and beauty) / shopee\n",
    "#--------------------------\n",
    "\n",
    "# data path\n",
    "bath_path_beauty = '../../grouping/tv_and_laptop_grouping/raw_data/beauty_personal_care/'\n",
    "sheet_name = 'Shopee input'\n",
    "personal_care_and_beauty_shopee = pd.read_excel(os.path.join(bath_path_beauty,'Face_Masks_BD.xlsx'),\n",
    "                                         sheet_name, skiprows = [0])\n",
    "# chang column name\n",
    "old_columns = personal_care_and_beauty_shopee.columns.tolist()\n",
    "new_columns = personal_care_and_beauty_shopee.iloc[0].values.tolist()\n",
    "personal_care_and_beauty_shopee = personal_care_and_beauty_shopee.rename(\n",
    "    columns = dict(zip(old_columns,new_columns))\n",
    "        )\n",
    "# data cleaning\n",
    "personal_care_and_beauty_shopee = personal_care_and_beauty_shopee.reset_index()\n",
    "# drop the first row by index\n",
    "personal_care_and_beauty_shopee.drop([0], inplace = True)\n",
    "# select the columns we only required\n",
    "personal_care_and_beauty_shopee = personal_care_and_beauty_shopee[['Item name','Brand','Product ']]\n",
    "# make the columns consistent with train\n",
    "personal_care_and_beauty_shopee = personal_care_and_beauty_shopee.rename(\n",
    "columns = {'Item name':'item_name', 'Brand':'what_brand_name', 'Product ': 'what_product_name'}\n",
    ")\n",
    "# cleaning duplicated item_name\n",
    "personal_care_and_beauty_shopee = personal_care_and_beauty_shopee.drop_duplicates(subset = ['item_name'])\n",
    "# convert type into str\n",
    "personal_care_and_beauty_shopee.item_name = personal_care_and_beauty_shopee.item_name.astype(str)\n",
    "personal_care_and_beauty_shopee.what_brand_name = personal_care_and_beauty_shopee.what_brand_name.astype(str)\n",
    "# take the sku that has confirmed ground truth as test\n",
    "personal_care_and_beauty_shopee = personal_care_and_beauty_shopee[\n",
    "personal_care_and_beauty_shopee.what_brand_name != 'Others'\n",
    "]\n",
    "# remove the bad case\n",
    "personal_care_and_beauty_shopee = personal_care_and_beauty_shopee[personal_care_and_beauty_shopee.what_brand_name != 'beauty mask']\n",
    "personal_care_and_beauty_shopee = personal_care_and_beauty_shopee[personal_care_and_beauty_shopee.what_brand_name != \"nan\"]\n",
    "# make the index unique\n",
    "personal_care_and_beauty_shopee.index = np.arange(personal_care_and_beauty_shopee.shape[0]) \n",
    "gc.collect()\n",
    "\n",
    "logging.info('there is no duplicated item in beauty' if personal_care_and_beauty_shopee.item_name.nunique() == personal_care_and_beauty_shopee.shape[0] else \"opps\")\n",
    "#--------------------------\n",
    "# loading data (beauty) / amazon\n",
    "#--------------------------\n",
    "beauty_amazon_path = '../../grouping/tv_and_laptop_grouping/raw_data/amazon/beauty_amazon.csv'\n",
    "beauty_amazon = pd.read_csv(beauty_amazon_path)\n",
    "beauty_amazon.item_name = beauty_amazon.item_name.astype(str)\n",
    "beauty_amazon.what_brand_name = beauty_amazon.what_brand_name.astype(str)\n",
    "beauty_amazon.dropna(subset = ['item_name'], axis = 0, inplace = True)\n",
    "\n",
    "#--------------------------\n",
    "# loading data (tv and laptop) / amazon\n",
    "#--------------------------\n",
    "tv_laptop_amazon_path = '../../grouping/tv_and_laptop_grouping/raw_data/amazon/tv_laptop_amazon.csv'\n",
    "tv_laptop_amazon = pd.read_csv(tv_laptop_amazon_path)\n",
    "tv_laptop_amazon.item_name = tv_laptop_amazon.item_name.astype(str)\n",
    "tv_laptop_amazon.what_brand_name = tv_laptop_amazon.what_brand_name.astype(str)\n",
    "tv_laptop_amazon.dropna(subset = ['item_name'], axis = 0, inplace = True)\n",
    "\n",
    "#--------------------------\n",
    "# validating strategy: train/val/test split based on the unique brand_name\n",
    "#--------------------------\n",
    "\n",
    "#-------------\n",
    "# tv & laptop / shopee\n",
    "#-------------\n",
    "tv_and_laptop_df = brand_split_validating_strategy(tv_and_laptop, train_val_rate = 0.5, dataset_source = 'Shopee')\n",
    "personal_care_and_beauty_shopee_df = brand_split_validating_strategy(personal_care_and_beauty_shopee, train_val_rate = 0.5, dataset_source = 'Shopee')\n",
    "# # check raw data first\n",
    "# personal_care_and_beauty_shopee_df.to_csv('data/face_mask_raw_data.csv', index = False)\n",
    "logging.info('thers is no bugging in validating strategy on tv_and_laptop/shopee' if tv_and_laptop_df.shape[0] == tv_and_laptop.shape[0] else 'bugging in combination')\n",
    "logging.info('thers is no bugging in validating strategy on personal_care_and_beauty_shopee/shopee' if personal_care_and_beauty_shopee_df.shape[0] == personal_care_and_beauty_shopee.shape[0] else 'bugging in combination')\n",
    "#--------------------------\n",
    "# create_supervised_data\n",
    "#--------------------------\n",
    "tv_and_laptop_df = tv_and_laptop_df.groupby('item_name').apply(sequence_labeling_w_bio_encoding).reset_index(drop = True)\n",
    "personal_care_and_beauty_shopee_df = personal_care_and_beauty_shopee_df.groupby('item_name').apply(sequence_labeling_w_bio_encoding).reset_index(drop = True)\n",
    "#--------------------------\n",
    "# training data eda report ==> transform to the percentage( unbranded product ratio)\n",
    "#--------------------------\n",
    "# 3c / shopee\n",
    "tv_df_stat = tv_and_laptop_df.groupby(by = 'item_name').is_brand.mean().to_frame().reset_index().sort_values('is_brand') \n",
    "num_item_without_positive_lable = tv_df_stat[tv_df_stat.is_brand == 0].shape[0]\n",
    "logging.info('ratio of sku in 3c cannot find brand name given his item_name /shopee : {} '.format(np.round(1.0 * num_item_without_positive_lable / len(tv_df_stat), 4)))\n",
    "# beauty / shopee\n",
    "beauty_df_stat = personal_care_and_beauty_shopee_df.groupby(by = 'item_name').is_brand.mean().to_frame().reset_index().sort_values('is_brand') \n",
    "num_item_without_positive_lable = beauty_df_stat[beauty_df_stat.is_brand == 0].shape[0]\n",
    "logging.info('ratio of sku in beauty cannot find brand name given his item_name / shopee: {}'.format(np.round(1.0 * num_item_without_positive_lable / len(beauty_df_stat), 4)))\n",
    "\n",
    "#--------------------------\n",
    "# drop all unbranded iten_name ( we want to keep a little bit to make machine can learn these examples) on amazon dataset\n",
    "#--------------------------\n",
    "tv_and_laptop_df = tv_and_laptop_df \\\n",
    "[~tv_and_laptop_df.item_name.isin(tv_df_stat[tv_df_stat.is_brand == 0].item_name.unique())]\n",
    "personal_care_and_beauty_shopee_df = personal_care_and_beauty_shopee_df \\\n",
    "[~personal_care_and_beauty_shopee_df.item_name.isin(beauty_df_stat[beauty_df_stat.is_brand == 0].item_name.unique())]\n",
    "\n",
    "# preprocessing\n",
    "personal_care_and_beauty_shopee_df = personal_care_and_beauty_shopee_df[personal_care_and_beauty_shopee_df.item_name != 'Kiehls Rare Earth Deep Pore Cleansing Masque \\r 14gr']\n",
    "tv_and_laptop_df.tokens = [np.nan if t == '' else t for t in tv_and_laptop_df.tokens]\n",
    "personal_care_and_beauty_shopee_df.tokens = [np.nan if t == '' else t for t in personal_care_and_beauty_shopee_df.tokens]\n",
    "tv_and_laptop_df.dropna(subset = ['tokens'], axis = 0, inplace = True)\n",
    "personal_care_and_beauty_shopee_df.dropna(subset = ['tokens'], axis = 0, inplace = True)\n",
    "\n",
    "#--------------------------\n",
    "# training data eda report ==> transform to the percentage( unbranded product ratio)\n",
    "#--------------------------\n",
    "# 3c / shopee\n",
    "tv_df_stat = tv_and_laptop_df.groupby(by = 'item_name').is_brand.mean().to_frame().reset_index().sort_values('is_brand') \n",
    "num_item_without_positive_lable = tv_df_stat[tv_df_stat.is_brand == 0].shape[0]\n",
    "logging.info('after drop, ratio of sku in 3c cannot find brand name given his item_name /shopee : {} '.format(np.round(1.0 * num_item_without_positive_lable / len(tv_df_stat), 4)))\n",
    "# beauty / shopee\n",
    "beauty_df_stat = personal_care_and_beauty_shopee_df.groupby(by = 'item_name').is_brand.mean().to_frame().reset_index().sort_values('is_brand') \n",
    "num_item_without_positive_lable = beauty_df_stat[beauty_df_stat.is_brand == 0].shape[0]\n",
    "logging.info('after drop, ratio of sku in beauty cannot find brand name given his item_name / shopee: {}'.format(np.round(1.0 * num_item_without_positive_lable / len(beauty_df_stat), 4)))\n",
    "\n",
    "gc.collect()\n",
    "#-------------\n",
    "# personal_care_and_beauty / amazon\n",
    "#-------------\n",
    "beauty_amazon_df = brand_split_validating_strategy(beauty_amazon, train_val_rate = 0.8, dataset_source = 'Amazon')\n",
    "logging.info('thers is no bugging in validating strategy on beauty/amazon' if beauty_amazon_df.shape[0] == beauty_amazon.shape[0] else 'bugging in combination')\n",
    "del beauty_amazon\n",
    "gc.collect()\n",
    "\n",
    "#-------------\n",
    "# tv&laptop / amazon\n",
    "#-------------\n",
    "tv_laptop_amazon_df = brand_split_validating_strategy(tv_laptop_amazon, train_val_rate = 0.8, dataset_source = 'Amazon')\n",
    "logging.info('thers is no bugging in validating strategy on tv_laptop/amazon' if tv_laptop_amazon_df.shape[0] == tv_laptop_amazon.shape[0] else 'bugging in combination')\n",
    "del tv_laptop_amazon\n",
    "gc.collect()\n",
    "#---------------------\n",
    "# preprocessing for distantly supervison method\n",
    "#---------------------\n",
    "beauty_amazon_df['count_of_what_brand_name_popping_out'] = [i_n.lower().count(b_n) for i_n, b_n in zip(beauty_amazon_df.item_name,\n",
    "                                                                            beauty_amazon_df.what_brand_name)]\n",
    "tv_laptop_amazon_df['count_of_what_brand_name_popping_out'] = [i_n.lower().count(b_n) for i_n, b_n in zip(tv_laptop_amazon_df.item_name,\n",
    "                                                                            tv_laptop_amazon_df.what_brand_name)]\n",
    "\n",
    "beauty_amazon_df = beauty_amazon_df[beauty_amazon_df.count_of_what_brand_name_popping_out <= 1]\n",
    "beauty_amazon_df.drop(['count_of_what_brand_name_popping_out'], axis = 1, inplace = True)\n",
    "\n",
    "tv_laptop_amazon_df = tv_laptop_amazon_df[tv_laptop_amazon_df.count_of_what_brand_name_popping_out <= 1]\n",
    "tv_laptop_amazon_df.drop(['count_of_what_brand_name_popping_out'], axis = 1, inplace = True)\n",
    "\n",
    "#--------------------------\n",
    "# create_supervised_data\n",
    "#--------------------------\n",
    "beauty_amazon_df = beauty_amazon_df.groupby('item_name').apply(sequence_labeling_w_bio_encoding).reset_index(drop = True)\n",
    "tv_laptop_amazon_df = tv_laptop_amazon_df.groupby('item_name').apply(sequence_labeling_w_bio_encoding).reset_index(drop = True)\n",
    "\n",
    "#--------------------------\n",
    "# training data eda report ==> transform to the percentage( unbranded product ratio)\n",
    "#--------------------------\n",
    "# 3c / amazone\n",
    "tv_df_stat = tv_laptop_amazon_df.groupby(by = 'item_name').is_brand.mean().to_frame().reset_index().sort_values('is_brand') \n",
    "num_item_without_positive_lable_tv = tv_df_stat[tv_df_stat.is_brand == 0].shape[0]\n",
    "logging.info('ratio of sku in 3c cannot find brand name given his item_name /amazon : {}'.format(np.round(1.0 * num_item_without_positive_lable / len(tv_df_stat), 4)))\n",
    "# beauty / amazone\n",
    "beauty_df_stat = beauty_amazon_df.groupby(by = 'item_name').is_brand.mean().to_frame().reset_index().sort_values('is_brand') \n",
    "num_item_without_positive_lable_beauty = beauty_df_stat[beauty_df_stat.is_brand == 0].shape[0]\n",
    "logging.info('ratio of sku in beauty cannot find brand name given his item_name / amazon: {}'.format(np.round(1.0 * num_item_without_positive_lable / len(beauty_df_stat), 4)))\n",
    "\n",
    "#--------------------------\n",
    "# preprocessing\n",
    "#--------------------------\n",
    "\n",
    "tv_laptop_amazon_df = tv_laptop_amazon_df[~tv_laptop_amazon_df.item_name.isin(tv_df_stat[tv_df_stat.is_brand == 0].item_name.unique())]\n",
    "beauty_amazon_df = beauty_amazon_df[~beauty_amazon_df.item_name.isin(beauty_df_stat[beauty_df_stat.is_brand == 0].item_name.unique())]\n",
    "tv_laptop_amazon_df.dropna(subset = ['tokens'], axis = 0, inplace = True)\n",
    "beauty_amazon_df.dropna(subset = ['tokens'], axis = 0, inplace = True)\n",
    "beauty_amazon_df = beauty_amazon_df[beauty_amazon_df.item_name != 'Ageless Answer Moisturizing Cream Gary Null 45 oz Cream']\n",
    "#--------------------------\n",
    "# Make the amazone dataset distribution closer to shopee dataset\n",
    "#--------------------------\n",
    "# TV\n",
    "tokens_count_df_amazon = tv_laptop_amazon_df.groupby('item_name').apply(lambda x: x.tokens.size) \\\n",
    ".to_frame('num_count').reset_index()\n",
    "tv_laptop_amazon_df = pd.merge(tv_laptop_amazon_df, tokens_count_df_amazon, on = 'item_name', how = 'left')\n",
    "tv_laptop_amazon_df = tv_laptop_amazon_df[tv_laptop_amazon_df.num_count <= 39]\n",
    "tv_laptop_amazon_df.drop(['num_count'], axis = 1, inplace = True)\n",
    "# Beauty\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_count_df = tv_and_laptop_df.groupby('item_name').apply(lambda x: x.tokens.size).to_frame('num_count').reset_index()\n",
    "shopee_longest_itemname_num = tokens_count_df.num_count.max() # int\n",
    "del tokens_count_df\n",
    "tokens_count_df_amazon = tv_laptop_amazon_df.groupby('item_name').apply(lambda x: x.tokens.size) \\\n",
    ".to_frame('num_count').reset_index()\n",
    "tv_laptop_amazon_df = pd.merge(tv_laptop_amazon_df, tokens_count_df_amazon, on = 'item_name', how = 'left')\n",
    "tv_laptop_amazon_df = tv_laptop_amazon_df[tv_laptop_amazon_df.num_count <= shopee_longest_itemname_num]\n",
    "tv_laptop_amazon_df.drop(['num_count'], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beauty\n",
    "tokens_count_df = personal_care_and_beauty_shopee_df.groupby('item_name').apply(lambda x: x.tokens.size).to_frame('num_count').reset_index()\n",
    "shopee_longest_itemname_num = tokens_count_df.num_count.max() # int\n",
    "del tokens_count_df\n",
    "tokens_count_df_amazon = beauty_amazon_df.groupby('item_name').apply(lambda x: x.tokens.size) \\\n",
    ".to_frame('num_count').reset_index()\n",
    "beauty_amazon_df = pd.merge(beauty_amazon_df, tokens_count_df_amazon, on = 'item_name', how = 'left')\n",
    "beauty_amazon_df = beauty_amazon_df[beauty_amazon_df.num_count <= shopee_longest_itemname_num]\n",
    "beauty_amazon_df.drop(['num_count'], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shopee_longest_itemname_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

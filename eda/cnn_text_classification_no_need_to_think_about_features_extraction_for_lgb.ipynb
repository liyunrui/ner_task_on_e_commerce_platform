{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "sys.path.append('../brand_detector/preprocessing')\n",
    "from clean_helpers import clean_name_for_word_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (836369, 4)\n",
      "val (8300, 4)\n",
      "test (21508, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "train    836369\n",
       "test      21508\n",
       "val        8300\n",
       "Name: eval_set, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = '../brand_detector/data/preprocessed'\n",
    "\n",
    "personal_care_and_beauty_shopee_df = pd.read_csv(os.path.join(output_dir, 'personal_care_and_beauty.csv'))\n",
    "beauty_amazon_df = pd.read_csv(os.path.join(output_dir, 'beauty_amazon.csv'))\n",
    "# configuration of shopee data: train/val/test = 35/15/50 (0,1,2)\n",
    "train = pd.concat([beauty_amazon_df, personal_care_and_beauty_shopee_df[personal_care_and_beauty_shopee_df.is_valid == 0]], axis = 0)\n",
    "val = personal_care_and_beauty_shopee_df[personal_care_and_beauty_shopee_df.is_valid == 1]\n",
    "test = personal_care_and_beauty_shopee_df[personal_care_and_beauty_shopee_df.is_valid == 2]\n",
    "del personal_care_and_beauty_shopee_df, beauty_amazon_df\n",
    "# preprocessing\n",
    "train['eval_set'] = ['train' for i in range(len(train))] \n",
    "val['eval_set'] = ['val' for i in range(len(val))] \n",
    "test['eval_set'] = ['test' for i in range(len(test))] \n",
    "train.drop(['is_valid'], axis =1, inplace = True)\n",
    "val.drop(['is_valid'], axis =1, inplace = True)\n",
    "test.drop(['is_valid'], axis =1, inplace = True)\n",
    "\n",
    "print ('train', train.shape)\n",
    "print ('val', val.shape)\n",
    "print ('test', test.shape)\n",
    "# all_df\n",
    "all_df = pd.concat([train, val, test], axis = 0)\n",
    "del train, test, val\n",
    "gc.collect()\n",
    "all_df.eval_set.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-trained word-embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_path = '/data/ID_large_wordvec_300_2.h5'\n",
    "word2vec = pd.read_hdf(word_embedding_path)\n",
    "# get word_to_id\n",
    "word_to_id = {word: int(i+1) for i, word in enumerate(word2vec.word.tolist())}\n",
    "# check\n",
    "assert word_to_id['dan'] == 1, 'wrong in our dict mapping word to id'\n",
    "assert word_to_id['di'] == 2, 'wrong in our dict mapping word to id'\n",
    "assert word_to_id['yang'] == 3, 'wrong in our dict mapping word to id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>dim_8</th>\n",
       "      <th>dim_9</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_291</th>\n",
       "      <th>dim_292</th>\n",
       "      <th>dim_293</th>\n",
       "      <th>dim_294</th>\n",
       "      <th>dim_295</th>\n",
       "      <th>dim_296</th>\n",
       "      <th>dim_297</th>\n",
       "      <th>dim_298</th>\n",
       "      <th>dim_299</th>\n",
       "      <th>dim_300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dan</td>\n",
       "      <td>0.712676</td>\n",
       "      <td>2.387824</td>\n",
       "      <td>-2.937458</td>\n",
       "      <td>5.594606</td>\n",
       "      <td>1.196547</td>\n",
       "      <td>3.567468</td>\n",
       "      <td>-0.333335</td>\n",
       "      <td>-1.570036</td>\n",
       "      <td>-1.445439</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.644627</td>\n",
       "      <td>0.048757</td>\n",
       "      <td>3.511451</td>\n",
       "      <td>-0.651203</td>\n",
       "      <td>2.474551</td>\n",
       "      <td>-0.118684</td>\n",
       "      <td>1.047346</td>\n",
       "      <td>2.676099</td>\n",
       "      <td>-3.377923</td>\n",
       "      <td>4.213373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>di</td>\n",
       "      <td>1.646574</td>\n",
       "      <td>3.004994</td>\n",
       "      <td>-2.030986</td>\n",
       "      <td>1.284245</td>\n",
       "      <td>2.100287</td>\n",
       "      <td>0.033384</td>\n",
       "      <td>0.991525</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.410926</td>\n",
       "      <td>...</td>\n",
       "      <td>1.630286</td>\n",
       "      <td>-5.025796</td>\n",
       "      <td>1.855228</td>\n",
       "      <td>1.364514</td>\n",
       "      <td>0.259180</td>\n",
       "      <td>2.906763</td>\n",
       "      <td>-2.368078</td>\n",
       "      <td>-1.652482</td>\n",
       "      <td>-5.045381</td>\n",
       "      <td>1.621557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yang</td>\n",
       "      <td>3.893595</td>\n",
       "      <td>1.641351</td>\n",
       "      <td>-4.073985</td>\n",
       "      <td>7.351041</td>\n",
       "      <td>0.277348</td>\n",
       "      <td>3.169405</td>\n",
       "      <td>1.772519</td>\n",
       "      <td>-1.548425</td>\n",
       "      <td>-3.901118</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.928375</td>\n",
       "      <td>-3.055444</td>\n",
       "      <td>3.708488</td>\n",
       "      <td>-0.407081</td>\n",
       "      <td>2.588052</td>\n",
       "      <td>-0.101883</td>\n",
       "      <td>-0.059166</td>\n",
       "      <td>-0.397024</td>\n",
       "      <td>-0.894873</td>\n",
       "      <td>4.231138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kami</td>\n",
       "      <td>4.253416</td>\n",
       "      <td>-1.777752</td>\n",
       "      <td>-4.561904</td>\n",
       "      <td>1.851718</td>\n",
       "      <td>0.782603</td>\n",
       "      <td>2.520426</td>\n",
       "      <td>0.912112</td>\n",
       "      <td>-1.305857</td>\n",
       "      <td>-2.840159</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.663830</td>\n",
       "      <td>-8.415740</td>\n",
       "      <td>3.040092</td>\n",
       "      <td>1.991707</td>\n",
       "      <td>1.335176</td>\n",
       "      <td>3.994257</td>\n",
       "      <td>4.258120</td>\n",
       "      <td>-0.209764</td>\n",
       "      <td>1.378407</td>\n",
       "      <td>0.395307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>untuk</td>\n",
       "      <td>-3.492490</td>\n",
       "      <td>3.062385</td>\n",
       "      <td>1.732885</td>\n",
       "      <td>6.494920</td>\n",
       "      <td>1.681367</td>\n",
       "      <td>1.559415</td>\n",
       "      <td>-0.851074</td>\n",
       "      <td>-0.963648</td>\n",
       "      <td>-1.843624</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.281300</td>\n",
       "      <td>-2.645144</td>\n",
       "      <td>-0.548235</td>\n",
       "      <td>-1.230889</td>\n",
       "      <td>-0.314143</td>\n",
       "      <td>0.879712</td>\n",
       "      <td>2.900071</td>\n",
       "      <td>0.650760</td>\n",
       "      <td>-5.747880</td>\n",
       "      <td>0.175559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    word     dim_1     dim_2     dim_3     dim_4     dim_5     dim_6  \\\n",
       "0    dan  0.712676  2.387824 -2.937458  5.594606  1.196547  3.567468   \n",
       "1     di  1.646574  3.004994 -2.030986  1.284245  2.100287  0.033384   \n",
       "2   yang  3.893595  1.641351 -4.073985  7.351041  0.277348  3.169405   \n",
       "3   kami  4.253416 -1.777752 -4.561904  1.851718  0.782603  2.520426   \n",
       "4  untuk -3.492490  3.062385  1.732885  6.494920  1.681367  1.559415   \n",
       "\n",
       "      dim_7     dim_8     dim_9    ...      dim_291   dim_292   dim_293  \\\n",
       "0 -0.333335 -1.570036 -1.445439    ...    -2.644627  0.048757  3.511451   \n",
       "1  0.991525  0.005785  0.410926    ...     1.630286 -5.025796  1.855228   \n",
       "2  1.772519 -1.548425 -3.901118    ...    -2.928375 -3.055444  3.708488   \n",
       "3  0.912112 -1.305857 -2.840159    ...    -2.663830 -8.415740  3.040092   \n",
       "4 -0.851074 -0.963648 -1.843624    ...    -4.281300 -2.645144 -0.548235   \n",
       "\n",
       "    dim_294   dim_295   dim_296   dim_297   dim_298   dim_299   dim_300  \n",
       "0 -0.651203  2.474551 -0.118684  1.047346  2.676099 -3.377923  4.213373  \n",
       "1  1.364514  0.259180  2.906763 -2.368078 -1.652482 -5.045381  1.621557  \n",
       "2 -0.407081  2.588052 -0.101883 -0.059166 -0.397024 -0.894873  4.231138  \n",
       "3  1.991707  1.335176  3.994257  4.258120 -0.209764  1.378407  0.395307  \n",
       "4 -1.230889 -0.314143  0.879712  2.900071  0.650760 -5.747880  0.175559  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_word_to_idx(x, word_to_id):\n",
    "    try:\n",
    "        return word_to_id[x]\n",
    "    except Exception:\n",
    "        # way1: take all the word that do not exist in word space as another word\n",
    "        return len(word_to_id)+1 \n",
    "# preprocessing\n",
    "all_df['clean_tokens'] = all_df.tokens.apply(lambda x: clean_name_for_word_embedding(x) if type(x)==str else x)\n",
    "all_df['clean_tokens'] = all_df.clean_tokens.apply(lambda x: x.lower() if type(x)==str else x)\n",
    "all_df['word_id'] = all_df.clean_tokens.apply( lambda x: encode_word_to_idx(x, word_to_id))\n",
    "#\n",
    "item_dict = {}\n",
    "for i, i_n in enumerate(all_df.item_name.unique().tolist()):\n",
    "    item_dict[i_n] = i+1\n",
    "all_df['item_id'] = [item_dict[i] for i in all_df.item_name.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_name</th>\n",
       "      <th>tokens</th>\n",
       "      <th>is_brand</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>word_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30394</th>\n",
       "      <td>NATURE REPUBLIC REAL SHEET MASK</td>\n",
       "      <td>NATURE</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>nature</td>\n",
       "      <td>4682</td>\n",
       "      <td>92823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30395</th>\n",
       "      <td>NATURE REPUBLIC REAL SHEET MASK</td>\n",
       "      <td>REPUBLIC</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>republic</td>\n",
       "      <td>11412</td>\n",
       "      <td>92823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30396</th>\n",
       "      <td>NATURE REPUBLIC REAL SHEET MASK</td>\n",
       "      <td>REAL</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>real</td>\n",
       "      <td>653</td>\n",
       "      <td>92823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30397</th>\n",
       "      <td>NATURE REPUBLIC REAL SHEET MASK</td>\n",
       "      <td>SHEET</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>sheet</td>\n",
       "      <td>5776</td>\n",
       "      <td>92823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30398</th>\n",
       "      <td>NATURE REPUBLIC REAL SHEET MASK</td>\n",
       "      <td>MASK</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>mask</td>\n",
       "      <td>2290</td>\n",
       "      <td>92823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30399</th>\n",
       "      <td>NATURE REPUBLIC REAL SHEET MASK 23gr</td>\n",
       "      <td>NATURE</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>nature</td>\n",
       "      <td>4682</td>\n",
       "      <td>92824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30400</th>\n",
       "      <td>NATURE REPUBLIC REAL SHEET MASK 23gr</td>\n",
       "      <td>REPUBLIC</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>republic</td>\n",
       "      <td>11412</td>\n",
       "      <td>92824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30401</th>\n",
       "      <td>NATURE REPUBLIC REAL SHEET MASK 23gr</td>\n",
       "      <td>REAL</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>real</td>\n",
       "      <td>653</td>\n",
       "      <td>92824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30402</th>\n",
       "      <td>NATURE REPUBLIC REAL SHEET MASK 23gr</td>\n",
       "      <td>SHEET</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>sheet</td>\n",
       "      <td>5776</td>\n",
       "      <td>92824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30403</th>\n",
       "      <td>NATURE REPUBLIC REAL SHEET MASK 23gr</td>\n",
       "      <td>MASK</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>mask</td>\n",
       "      <td>2290</td>\n",
       "      <td>92824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30404</th>\n",
       "      <td>NATURE REPUBLIC REAL SHEET MASK 23gr</td>\n",
       "      <td>23gr</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>23gr</td>\n",
       "      <td>112141</td>\n",
       "      <td>92824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50495</th>\n",
       "      <td>NATURE REPUBLIC REAL SHEET MASK</td>\n",
       "      <td>NATURE</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>nature</td>\n",
       "      <td>4682</td>\n",
       "      <td>93906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50496</th>\n",
       "      <td>NATURE REPUBLIC REAL SHEET MASK</td>\n",
       "      <td>REPUBLIC</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>republic</td>\n",
       "      <td>11412</td>\n",
       "      <td>93906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50497</th>\n",
       "      <td>NATURE REPUBLIC REAL SHEET MASK</td>\n",
       "      <td>REAL</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>real</td>\n",
       "      <td>653</td>\n",
       "      <td>93906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50498</th>\n",
       "      <td>NATURE REPUBLIC REAL SHEET MASK</td>\n",
       "      <td>SHEET</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>sheet</td>\n",
       "      <td>5776</td>\n",
       "      <td>93906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50499</th>\n",
       "      <td>NATURE REPUBLIC REAL SHEET MASK</td>\n",
       "      <td>MASK</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>mask</td>\n",
       "      <td>2290</td>\n",
       "      <td>93906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  item_name    tokens  is_brand eval_set  \\\n",
       "30394       NATURE REPUBLIC REAL SHEET MASK    NATURE         2     test   \n",
       "30395       NATURE REPUBLIC REAL SHEET MASK  REPUBLIC         1     test   \n",
       "30396       NATURE REPUBLIC REAL SHEET MASK      REAL         0     test   \n",
       "30397       NATURE REPUBLIC REAL SHEET MASK     SHEET         0     test   \n",
       "30398       NATURE REPUBLIC REAL SHEET MASK      MASK         0     test   \n",
       "30399  NATURE REPUBLIC REAL SHEET MASK 23gr    NATURE         2     test   \n",
       "30400  NATURE REPUBLIC REAL SHEET MASK 23gr  REPUBLIC         1     test   \n",
       "30401  NATURE REPUBLIC REAL SHEET MASK 23gr      REAL         0     test   \n",
       "30402  NATURE REPUBLIC REAL SHEET MASK 23gr     SHEET         0     test   \n",
       "30403  NATURE REPUBLIC REAL SHEET MASK 23gr      MASK         0     test   \n",
       "30404  NATURE REPUBLIC REAL SHEET MASK 23gr      23gr         0     test   \n",
       "50495      NATURE REPUBLIC REAL SHEET MASK     NATURE         2     test   \n",
       "50496      NATURE REPUBLIC REAL SHEET MASK   REPUBLIC         1     test   \n",
       "50497      NATURE REPUBLIC REAL SHEET MASK       REAL         0     test   \n",
       "50498      NATURE REPUBLIC REAL SHEET MASK      SHEET         0     test   \n",
       "50499      NATURE REPUBLIC REAL SHEET MASK       MASK         0     test   \n",
       "\n",
       "      clean_tokens  word_id  item_id  \n",
       "30394       nature     4682    92823  \n",
       "30395     republic    11412    92823  \n",
       "30396         real      653    92823  \n",
       "30397        sheet     5776    92823  \n",
       "30398         mask     2290    92823  \n",
       "30399       nature     4682    92824  \n",
       "30400     republic    11412    92824  \n",
       "30401         real      653    92824  \n",
       "30402        sheet     5776    92824  \n",
       "30403         mask     2290    92824  \n",
       "30404         23gr   112141    92824  \n",
       "50495       nature     4682    93906  \n",
       "50496     republic    11412    93906  \n",
       "50497         real      653    93906  \n",
       "50498        sheet     5776    93906  \n",
       "50499         mask     2290    93906  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df[all_df.item_name.str.contains('NATURE REPUBLIC REAL SHEET MASK')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare_training_data\n",
    "\n",
    "# output:\n",
    "# -item_id: for creating own item_embedding\n",
    "# -word_id: for matching word_embedding\n",
    "# -final_states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 1199.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sequences : 93909\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def pad_1d(array, max_len):\n",
    "    array = array[:max_len]\n",
    "    length = len(array)\n",
    "    padded = array + [0]*(max_len - len(array))\n",
    "    return padded, length\n",
    "\n",
    "#-------------------\n",
    "# setting\n",
    "#-------------------\n",
    "TRUNCATED = False\n",
    "num_sentences = all_df['item_name'].nunique()\n",
    "seq_len_distribution = all_df.head(100).groupby('item_name').tokens.apply( lambda x : len(x.tolist())).to_frame('seq_len').reset_index()\n",
    "\n",
    "if TRUNCATED == False:\n",
    "    max_seq_length = seq_len_distribution.seq_len.max()\n",
    "else:\n",
    "    max_seq_length = 100\n",
    "#-------------------\n",
    "# output\n",
    "#-------------------\n",
    "print ('number of sequences : {}'.format(num_sentences))\n",
    "# 1-D\n",
    "eval_set = np.zeros(shape=[num_sentences], dtype='S5')\n",
    "item_id = np.zeros(shape=[num_sentences], dtype=np.int32)\n",
    "history_length = np.zeros(shape=[num_sentences], dtype=np.int8)\n",
    "# 2-D\n",
    "word_id = np.zeros(shape=[num_sentences, max_seq_length], dtype=np.int32)\n",
    "label = np.zeros(shape=[num_sentences, max_seq_length], dtype=np.int8)\n",
    "i = 0\n",
    "for ix, df in tqdm(all_df.head(50).groupby('item_name')):\n",
    "    # 1-d\n",
    "    eval_set[i] = df['eval_set'].iloc[0]\n",
    "    item_id[i] = df['item_id'].iloc[0]\n",
    "    # 2-d\n",
    "    word_id[i, :], history_length[i] = pad_1d(list(map(int, df['word_id'])), \n",
    "                                              max_len = max_seq_length)\n",
    "    label[i, :], _ = pad_1d(list(map(int, df['is_brand'])), \n",
    "                                              max_len = max_seq_length)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93909, 14)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93909, 14)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../brand_detector/data/preprocessed/eval_set.npy', eval_set)\n",
    "np.save('../brand_detector/data/preprocessed/item_id.npy', item_id)\n",
    "np.save('../brand_detector/data/preprocessed/word_id.npy', word_id)\n",
    "np.save('../brand_detector/data/preprocessed/history_length.npy', history_length)\n",
    "np.save('../brand_detector/data/preprocessed/label.npy', label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
